---
title: 《ClickHouse原理解析与应用实践》笔记
date: 2021-10-17 21:39:44
permalink: /clickhouse/2ej52zhljzx1w52w/
categories:
  - clickhouse
  - 数据库
tags:
  - clickhouse
author: 
  name: nrnc
  link: https://github.com
---

> 说明：本章内容为博主在原教程基础上添加自己的学习笔记，来源[《ClickHouse原理解析与应用实践》](https://book.douban.com/subject/35091211/)，版权归原作者所有。

------

**文档地址：**

pdf下载地址：[《ClickHouse原理解析与应用实践》](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/pdf/ClickHouse%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5.pdf)

官方文档地址：<https://clickhouse.com/docs/zh/>



## 一、架构概述

**名词术语** ：
**OLTP(Online Transaction Processing)** 联机事务处理  
**OLAP(Online Analytical Processing)**  联机分析技术：常见架构：
- ROLAP(Relational OLAP，关系型OLAP)  建立在关系型数据库之上，直接sql查询，缺点：性能差 
- MOLAP(Multidimensional OLAP，多维型OLAP)     对各种维度进行组合并事先聚合，保存，供之后查询。缺点：数据量可能会膨胀10-20倍，存在滞后性、更新问题 
- HOLAP(Hybrid OLAP，混合架构的OLAP)  以上两种结合 

**LSM树**
> 发源于Google的BigTable，最具代表性系统HBase。LSM树本质上可以看作将原本的一棵大树拆成许多棵小树。每一批次写入的数据都会经历如下过程。
> 首先，会在内存中构建一棵小树，构建完毕即算写入成功（这里会通过预写日志的形式，防止因内存故障而导致的数据丢失）。写入动作只发生在内存中，不涉及磁盘操作，所以极大提升了
> 数据写入性能。其次，小树在构建的过程中会进行排序，就保证了数据的有序性。最后，当内存中小树的数量达到某个阈值时，就会借助后台线程将小树刷入磁盘并生成一个小的数据段。在
> 每个数据段中，数据局部有序。也正因为数据有序，所以能够进一步使用稀疏索引来优化查询性能。


**MPP 架构**:
MPP是系统架构角度的一种服务器分类方法。目前商用服务器分类大体三种: 

1. SMP对称多处理器结构;
2. NUMA非一致存储访问结构
3. MPP大规模并行处理结构。

**SMP**
服务器的多个CPU对称工作，无主次或从属关系。系统中的所有资源CPU、内存、IO等都是共享的。扩展能力非常有限。 
**NUMA**
可以把几十个CPU组合在一台服务器内。基本特征是拥有多个CPU模块，节点之间你可以通过互联模块进行链接和信息交互。所以每个CPU可以访问整个系统的内存。但是访问速度是不一样的，因为CPU访问本地内存远远高于系统内其他节点的内存速度，这也是非一致存储访问NUMA由来。 
**MPP**
MPP是有多台SMP服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户角度来看是一个服务器系统。每个节点只访问自己的资源，所以是一种完全无共享结构。 
*特征：任务并行执行、数据分布式存储本地化、分布式计算、高并发，单个节点并发能力大于300用户、横向扩展，支持集群节点的扩容、Shared Nothing架构*。 

 ### 1. clickhouse 核心特性

1. 完备的DBMS功能
   1. **DDL 数据定义语言**：可以动态地创建、修改或删除数据库、表和视图，而无须重启服务。
   2. **DML 数据操作语言**：可以动态查询、插入、修改或删除数据。
   3. 权限控制：可以按照用户粒度设置数据库或者表的操作权限；
   4. 数据备份与恢复： 提供数据备份导出和导入恢复机制；
   5. 分布式管理：提供集群模式，能自动管理多个数据库节点；
2. 列示存储与数据压缩

   数据按列进行组织，属于同一列数据会保存在一起，列与列之间会由不同文件分别保存（主要指MergerTree表引擎）。数据默认使用LZ4算法压缩

3. 向量化执行引擎

   为了实现向量化执行，需要利用CPU的SIMD指令。SIMD的全称是Single Instruction Multiple Data，即用单条指令操作多条数据。原理是在CPU寄存器层面实现数据并行操作。

4. 关系模型与sql查询
5. 多样化的表引擎
6. 多线程与分布式
7. 多主架构
8. 在线查询
9. 数据分片与分布式查询

​    **ClickHouse支持分片，而分片则依赖集群**。每个集群由1到多个分片组成，而每个分片则对应了ClickHouse的1个服务节点。分片的数量上限取决于节点数量（1个分片只能对应1个服务节点）。  

   提供了本地表与分布式表概念。一张本地表等同于一份数据的分片。而分布式表本身不存储任何数据，它是本地表的访问代理，其作用类似分库中间件。

   借助分布式表，能够代理访问多个数据分片， 从而实现分布式查询。



### 2. clickhouse 架构设计



![核心模块](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-16_16-44-01.png)



## 二、数据定义

### 1.clickhouse的数据类型

#### 1.1 基础数据类型

1. 数值类型

   - int 有符号整数 Int8、Int16、Int32、Int64  =》（Tinyint、Smallint、Int和Bigint）

     无符号整数 UInt8、UInt16、UInt32、UInt64

   - Float  Float32、Float64 

   - Decimal

     ![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-16_16-51-40.png)

2. 字符串类型

- - String  长度不限
  - FixedString   固定长度的字符串，以null字节填充末尾字符。
  - UUID   共有32位，格式为8-4-4-4-12. 默认用0填充。

3. 时间类型

   时间类型最高精度是秒，如需毫秒更小单位，借助UInt实现。

   - DateTime  精确到秒，支持用字符串形式写入。
   - DateTime64  可以记录亚秒，在DateTime之上增加了精度的设置
   - Date  只精确到天，支持字符串写入



#### 1.2 复合类型

数组、元组、枚举、嵌套

1. Array

```sql
select [1, 2]
-- or
select array(1,2) as a, toTypeNmae(a)
-- create table
create table Array_Test(
    c1 Array(string) -- 需指定元素类型
) engine = Memory
```

2. Tuple

元组类型由1～n个元素组成，每个元素之间允许设置不同的数据类型，且彼此之间不要求兼容。同样支持类型推断，以最小存储代价为原则。 

`create table t(t1 Tuple(String, Int8)) engine=Memory`

3. Enum

   Enum8、Enum16

​	枚举固定使用(String:Int) Key/Value 键值对 形式定义数据 Enum8和Enum16分别会对应(String:Int8)和(String:Int16)；

​	在写入枚举数据的时候，只会用到Key字符串部分，但在后续对枚举的所有操作（排序、分组、去重、过滤等）只会用Int类型的Value值.

```sql
REATE TABLE Enum_TEST (
c1 Enum8('ready' = 1, 'start' = 2, 'success' = 3, 'error' = 4)
) ENGINE = Memory;

INSERT INTO Enum_TEST VALUES('ready');

-- only insert ready\start\success\error
-- INSERT INTO Enum_TEST VALUES('stop');  throw error
```

4. Nested

一张数据表，可以定义任意多个嵌套类型字段，但每个字段的嵌套层级只支持一级，即嵌套表内不能继续使用嵌套类型。声明如下：

```sql
CREATE TABLE nested_test (
name String,
age UInt8 ,
dept Nested(
    id UInt8,
    name String)
) ENGINE = Memory;
```

嵌套类型本质是一种多维数组的结构。嵌套表中的每个字段都是一个数组，并且行与行之间数组的长度无须对齐。 

`INSERT INTO nested_test VALUES ('bruce' , 30 , [10000,10001,10002], ['研发部','技术支持中心','测试部']);`

在访问嵌套类型的数据时需要使用点符号:

```sql
SELECT name, dept.id, dept.name FROM nested_test
┌─name─┬─dept.id──┬─dept.name─────────────┐
│ bruce │ [16,17,18] │ ['研发部','技术支持中心','测试部'] │
└────┴───────┴────────────────────┘
```



#### 1.3 特殊类型

1. Nullable  

可修饰字段表示能写入null值。慎用，如果一个列字段被Nullable修饰后，会额外生成一个[Column].null.bin 文件专门保存它的null值。

2. Domain

分为IPv4和IPv6，本质上是对整型和字符串的进一步封装。 IPv4 基于UInt32封装，IPv6基于FixedString(16)封装。

```sql
CREATE TABLE IP4_TEST (
url String,
ip IPv4
) ENGINE = Memory;
INSERT INTO IP4_TEST VALUES ('www.nauu.com','192.0.0.0')
SELECT url , ip ,toTypeName(ip) FROM IP4_TEST
┌─url──────┬─────ip─┬─toTypeName(ip)─┐
│ www.nauu.com │ 192.0.0.0 │ IPv4 │
└────────┴───────┴──────────┘
```

如果需要返回IP的字符串形式，则需要显式调用IPv4NumToString或IPv6NumToString函数进行转换



### 2.数据表定义-todo



### 3.数据表的基本操作-todo



### 4.数据分区的执行-todo



### 5.分布式DDL执行

将一条普通的DDL语句转换成分布式执行十分简单，只需加上ON CLUSTER cluster_name声明即可。例如，执行下面的语句后将会对ch_cluster集群内的所有节点广播这条DDL语句：

```sql
CREATE TABLE partition_v3 ON CLUSTER ch_cluster(
ID String,
URL String,
EventTime Date
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(EventTime)
ORDER BY ID
```



### 6.数据的写入

- 使用values格式

  ```sql
  INSERT INTO [db.]table [(c1, c2, c3…)] VALUES (v11, v12, v13…), (v21, v22, v23…)
  ```

- 使用指定格式

  ```sql
  INSERT INTO [db.]table [(c1, c2, c3…)] FORMAT format_name data_set
  
  INSERT INTO partition_v2 FORMAT CSV \
  'A0017','www.nauu.com', '2019-10-01' \
  'A0018','www.nauu.com', '2019-10-01'
  ```

- 使用select子句

  ```sql
  INSERT INTO [db.]table [(c1, c2, c3…)] SELECT ...
  ```



>ClickHouse内部所有的数据操作都是面向Block数据块的，所以INSERT查询最终会将数据转换为Block数据块。也正因如此，INSERT语句在单个数据块的写入过程中是具有原子性的。在默认的情况下，每个数据块最多可以写入1048576行数据（由max_insert_block_size参数控制）。也就是说，如果一条INSERT语句写入的数据少于max_insert_block_size行，那么这批数据的写入是具有原子性的，即要么全部成功，要么全部失败。需要注意的是，**只有在ClickHouse服务端处理数据的时候才具有这种原子写入的特性**，例如使用JDBC或者HTTP接口时。因为max_insert_block_size参数在使用CLI命令行或者INSERT SELECT子句写入时是不生效的。



### 7.数据的删除与修改

ClickHouse提供了DELETE和UPDATE的能力，这类操作被称为Mutation查询，它可以看作ALTER语句的变种。

**与传统update和delete的区别** :

- 首先，Mutation语句是一种“很重”的操作，更适用于批量数据的修改和删除；

- 其次，它不支持事务，一旦语句被提交执行，就会立刻对现有数据产生影响，无法回滚；

- 最后，Mutation语句的执行是一个异步的后台过程，语句被提交之后就会立即返回。所以这并不代表具体逻辑已经执行完毕，它的具体执行进度需要通过system.mutations系统表查询。



## 三、数据字典-TODO



## 四、MergeTree原理解析

### 1. 创建方式和存储结构

#### 1.1 创建方式

声明sql：

```sql
CREATE TABLE [IF NOT EXISTS] [db_name.]table_name (
name1 [type] [DEFAULT|MATERIALIZED|ALIAS expr],
name2 [type] [DEFAULT|MATERIALIZED|ALIAS expr],
省略...
) ENGINE = MergeTree()
[PARTITION BY expr]
[ORDER BY expr]
[PRIMARY KEY expr]
[SAMPLE BY expr]
[SETTINGS name=value, 省略...]
```

- PARTITION BY [选填]：分区键，用于指定表数据以何种标准进行分区；
- ORDER BY [必填]：排序键，用于指定在一个数据片段内，数据以何种标准排序。默认情况下主键（PRIMARY KEY）与排序键相同。
- PRIMARY KEY [选填]：主键，声明后会依照主键字段生成一级索引，用于加速表查询。通常直接使用ORDER BY代为指定主键，无须刻意通过PRIMARY KEY声明。
- SAMPLE BY [选填]：抽样表达式，用于声明数据以何种标准进行采样。
- SETTINGS：index_granularity [选填]：index_granularity对于MergeTree而言是一项非常重要的参数，它表
  示索引的粒度，默认值为8192。也就是说，MergeTree的索引在默认情况下，每间隔8192行数据才生成一条索引。
- SETTINGS：index_granularity_bytes [选填]:自适应间隔大小的特性，即根据每一批次写入数据的体量大小，动态划分间隔大小。而数据的体量大小，正是由index_granularity_bytes参数控制的，默认为10M(10×1024×1024)，设置为0表示不启动自适应功能。
- SETTINGS：enable_mixed_granularity_parts [选填]：设置是否开启自适应索引间隔的功能，默认开启。

#### 1.2 存储结构

完整的存储结构

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-16_17-18-59.png)

1. partition：分区目录，余下各类数据文件（primary.idx、[Column].mrk、[Column].bin等）都是以分区目录的形式被组织存放的，属于相同分区的数据；

2. checksums.txt：校验文件，使用二进制格式存储。它保存了余下各类文件(primary.idx、count.txt等)的size大小及size的哈希值，用于快速校验文件的完整性和正确性；

3. columns.txt：列信息文件，使用明文格式存储。用于保存此数据分区下的列字段信息；

4. count.txt：计数文件，使用明文格式存储。用于记录当前数据分区目录下数据的总行数；

5. primary.idx：一级索引文件，使用二进制格式存储。用于存放稀疏索引，一张MergeTree表只能声明一次一级索引（通过ORDER BY或者PRIMARY KEY）。

6. [Column].bin：数据文件，使用压缩格式存储，默认为LZ4压缩格式，用于存储某一列的数据。

7. [Column].mrk：列字段标记文件，使用二进制格式存储。标记文件中保存了.bin文件中数据的偏移量信息。标记文件与稀疏索引对齐，又与.bin文件一一对应，所以MergeTree通过标记文件建立了primary.idx稀疏索引与.bin数据文件之间的映射关系。

   >即首先通过稀疏索引（primary.idx）找到对应数据的偏移量信息（.mrk），再通过偏移量直接从.bin文件中读取数据。由于.mrk标记文件与.bin文件一一对应，所以MergeTree中的每个列字段都会拥有与其对应的.mrk标记文件（例如CounterID.mrk、EventDate.mrk等）。

8. [Column].mrk2：如果使用了自适应大小的索引间隔，则标记文件会以.mrk2命名。它的工作原理和作用与.mrk标记文件相同。

9. partition.dat与minmax_[Column].idx：如果使用了分区键，例如PARTITION BY EventTime，则会额外生成partition.dat与minmax索引文件，它们均使用二进制格式存储。

   > partition.dat用于保存当前分区下分区表达式最终生成的值；而minmax索引用于记录当前
   > 分区下分区字段对应原始数据的最小和最大值。 例如EventTime字段对应的原始数据为2019-05-01、2019-05-05，分区表达式为PARTITION BY toYYYYMM(EventTime)。partition.dat中保存的值将会是2019-05，而minmax索引中保存的值将会是2019-05-012019-05-05。

10. skp_idx_[Column].idx与skp_idx_[Column].mrk：如果在建表语句中声明了二级索引，则会额外生成相应的二级索引与标记文件，它们同样也使用二进制存储。二级索引在ClickHouse中又称跳数索引，目前拥有minmax、set、ngrambf_v1和tokenbf_v1四种类型。



### 2. 数据分区

#### 2.1 分区规则

1. 不指定分区键：如果不使用分区键，即不使用PARTITION BY声明任何分区表达式，则分区ID默认取名为all，所有的数据都会被写入这个all分区；
2. 使用整型：如果分区键取值属于整型（兼容UInt64，包括有符号整型和无符号整型），且无法转换为日期类型YYYYMMDD格式，则直接按照该整型的字符形式输出，作为分区ID的取值。
3. 使用日期类型：如果分区键取值属于日期类型，或者是能够转换为YYYYMMDD格式的整型，则使用按照YYYYMMDD进行格式化后的字符形式输出，并作为分区ID的取值。
4. 使用其他类型：如果分区键取值既不属于整型，也不属于日期类型，例如String、Float等，则通过128位Hash算法取其Hash值作为分区ID的取值。

#### 2.2 分区目录命名和合并过程-todo



### 3. 一级索引

主键定义之后，MergeTree会依据**index_granularity**间隔（默认**8192**行），为数据表生成一级索引并保存至primary.idx文件内，索引数据按照PRIMARY KEY排序。

#### 3.1 稀疏索引

![稀疏索引和稠密索引区别](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-16_17-11-53.png)

索引粒度 默认8192，则MergeTree只需要12208行索引标记就能为1亿行数据提供索引。由于占用空间小，所以primary.idx内的索引数据可常驻内存。



#### 3.2 索引粒度

**index_granularity**的命名虽然取了索引二字，但它不单只作用于一级索引（.idx），同时也会影响数据标记（.mrk）和数据文件（.bin）。

因为仅有一级索引自身是无法完成查询工作的，它需要借助数据标记才能定位数据，所以一级索引和数据标记的间隔粒度相同（同为index_granularity行），彼此对齐。

数据文件也会依照index_granularity的间隔粒度生成压缩数据块。



#### 3.3 索引查询过程

MarkRange在ClickHouse中是用于定义标记区间的对象；MergeTree按照index_granularity的间隔粒度，将一段完整的数据划分成了多个小的间隔数据段（n/index_granularity），一个具体的数据段即是一个MarkRange。

MarkRange与索引编号对应，使用start和end两个属性表示其区间范围。

**索引查询过程可以大致分为3个步骤**：

1. 生成查询条件区间：将查询条件转换为条件区间。
2. 递归交集判断：以递归的形式，依次对MarkRange的数值区间与条件区间做交集判断。从最大的区间[A000,+inf)开始：
   - 不存在交集，则直接通过剪枝算法优化此整段MarkRange。
   - 存在交集，且MarkRange步长大于8(end-start)，则将此区间进一步拆分成8个子区间（merge_tree_coarse_index_granularity指定，默认值为8），并重复此规则，继续做递归交集判断；
   - 如果存在交集，且MarkRange不可再分解（步长小于8），则记录MarkRange并返回。

3. 合并MarkRange区间：将最终匹配的MarkRange聚在一起，合并范围。

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_10-19-55.png)





### 4. 二级索引

跳数索引需要在CREATE语句内定义，它支持使用元组和表达式的形式声明:

`INDEX index_name expr TYPE index_type(...) GRANULARITY granularity`;

与一级索引一样，如果在建表语句中声明了跳数索引，则会额外生成相应的索引与标记文（skp_idx_[Column].idx与 skp_idx _ [Column].mrk）



**granularity与index_granularity**：

不同的跳数索引之间，除了它们自身独有的参数之外，还都共同拥有granularity参数。

**index_granularity定义了数据的粒度，** 而**granularity定义了一行跳数索引能够跳过多**
**少个index_granularity区间的数据。**



**跳数索引的数据生成规则**：首先按照index_granularity粒度间隔将数据划分成n段，总共有[0,n-1]个区间；接着，根据索引定义时声明的表达式，从0区间开始，依次按index_granularity粒度从数据中获取聚合信息，每次向前移动1步，聚合信息逐步累加。最后，当移动granularity次区间时，则汇总并生成一行跳数索引数据。

如： ![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_11-25-53.png)



#### 4.1跳数索引的类型

一张表支持同时声明多个跳数索引：

```sql
CREATE TABLE skip_test (
ID String,
URL String,
Code String,
EventTime Date,
INDEX a ID TYPE minmax GRANULARITY 5,
INDEX b（length(ID) * 8） TYPE set(2) GRANULARITY 5,
INDEX c（ID，Code） TYPE ngrambf_v1(3, 256, 2, 0) GRANULARITY 5,
INDEX d ID TYPE tokenbf_v1(256, 2, 0) GRANULARITY 5
) ENGINE = MergeTree()
...
```

##### 1.1 minmax

minmax索引记录了一段数据内的最小和最大极值，其索引的作用类似分区目录的minmax索引，能够快速跳过无用的数据区间。如： `INDEX a ID TYPE minmax GRANULARITY 5`

##### 1.2 set

set索引直接记录了声明字段或表达式的取值（唯一值，无重复），其完整形式为set(max_rows)，其中max_rows是一个阈值，表示在一个index_granularity内，索引最多记录的数据行数。

max_rows=0，则表示无限制。

##### 1.3 ngrambf_v1

ngrambf_v1索引记录的是数据短语的布隆表过滤器，只支持String和FixedString数据类型。ngrambf_v1只能够提升in、notIn、like、equals和notEquals查询的性能，其完整形式为 ngrambf_v1(n,size_of_bloom_filter_in_bytes,number_of_hash_functions,random_seed)。这些参数是一个布隆过滤器的标准输入，如果你接触过布隆过滤器，应该会对此十分熟悉。

它们具体的含义如下:

- - n：token长度，依据n的长度将数据切割为token短语。
  - size_of_bloom_filter_in_bytes：布隆过滤器的大小。
  - number_of_hash_functions：布隆过滤器中使用Hash函数的个数。
  - random_seed：Hash函数的随机种子。

例如在上面的例子中，ngrambf_v1索引会依照3的粒度将数据切割成短语token，token会经过2个Hash函数映射后再被写入，布隆过滤器大小为256字节。

##### 1.4 tokenbf_v1

tokenbf_v1索引是ngrambf_v1的变种，同样也是一种布隆过滤器索引。tokenbf_v1除了短语token的处理方法外，其他与ngrambf_v1是完全一样的。

tokenbf_v1会自动按照非字符的、数字的字符串分割token。



### 5.数据存储

#### 5.1 各列独立存储

首先，数据是经过压缩的，目前支持LZ4、ZSTD、Multiple和Delta几种算法，默认使用
LZ4算法；其次，数据会事先依照ORDER BY的声明排序；最后，数据是以压缩数据块的形式被组织并写入.bin文件中的。

#### 5.2 数据压缩

一个压缩数据块由头信息和压缩数据两部分组成。头信息固定使用9位字节表示，具体由1个UInt8（1字节）整型和2个UInt32（4字节）整型组成，分别代表使用的压缩算法类型、压缩后的数据大小和压缩前的数据大小。

每个待压缩数据块的体积，按照其压缩前的数据字节大小，都被严格控制在64KB～1MB，其上下限分别由min_compress_block_size（默认65536）与max_compress_block_size（1048576）指定。

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_11-41-53.png)

### 6. 数据标记

> primary.idx一级索引好比书的一级章节目录，.bin文件中的数据好比这本书中的文字，标记(.mrk)会为一级章节目录和具体的文字之间建立关联。 记录了两点重要信息：
>
> 其一，是一级章节对应的页码信息；其二，是一段文字在某一页中的起始位置信息。
>
> 标记数据与一级索引数据不同，它并不能常驻内存，而是使用LRU（最近最少使用）缓存策略加快其取用速度。

#### 6.1 生成规则

一行标记数据使用一个元组表示，元组内包含两个整型数值的偏移量信息。它们分别表示在此段数据区间内，在对应的.bin压缩文件中，压缩数据块的起始偏移量；以及将该数据压缩块解压后，其未压缩数据的起始偏移量。

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_21-14-13.png)



#### 6.2 工作方式

整个查找过程大致可以分为读取压缩数据块和读取数据两个步骤

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_21-06-06.png)

说明：

（1）读取压缩数据块： 在查询某一列数据时，MergeTree无须一次性加载整个.bin文件，而是可以根据需要，只加载特定的压缩数据块。而这项特性需要借助标记文件中所保存的压缩文件中的偏移量。在图6-19所示的标记数据中，上下相邻的两个压缩文件中的起始偏移量，构成了与获取当前标记对应的压缩数据块的偏移量区间。**由**
**当前标记数据开始，向下寻找，直到找到不同的压缩文件偏移量为止。**此时得到的一组偏移量区间即是压缩数据块在.bin文件中的偏移量。例如在图6-19所示中，读取右侧.bin文件中[0，12016]字节数据，就能获取第0个压缩数据块。

（2）读取数据： 在读取解压后的数据时，MergeTree并不需要一次性扫描整段解压数据，它可以根据需要，以index_granularity的粒度加载特定的一小段。为了实现这项特性，需要借助标记文件中保存的解压数据块中的偏移量。  同样的，在图6-19所示的标记数据中，上下相邻两个解压缩数据块中的起始偏移量，构成了与获取当前标记对应的数据的偏移量区间。通过这个区间，能够在它的压缩块被解压之后，依照偏移量按需读取数据。例如在图6-19所示中，通过[0，8192]能够读取压缩数据块0中的第一个数据片段。



### 7. 总结

#### 7.1 写入

生成分区目录，每一批数据写入都会生成一个新的分区目录，在后续某一时刻由后台线程 将相同分区的目录依照规则合并。接着按照index_granularity索引粒度，

分别生成Primary.idx一级索引（如果声明二级索引，还会创建二级索引文件）、每一列字段的.mrk数据标记和.bin压缩数据文件。

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_21-22-27.png)

#### 7.2 查询

MergeTree首先可以依次借助**分区索引、一级索引和二级索引**，将数据扫描范围缩至最小。然后再**借助数据标记**，将需要解压与计算的数据范围缩至最小。

如果条件没有匹配任何索引，只能借助数据标记，通过多线程形式同时读取多个压缩数据块，以提升性能。

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_21-23-48.png)



## 五、MergeTree系列表引擎

MergeTree、ReplacingMergeTree、SummingMergeTree、AggregatingMergeTree、CollapsingMergeTree和
VersionedCollapsingMergeTree。

### 1. MergeTree

#### 1.1 数据TTL

##### 1.1.1 列级别TTL

```sql
CREATE TABLE ttl_table_v1(
id String,
create_time DateTime,
code String TTL create_time + INTERVAL 10 SECOND,
type UInt8 TTL create_time + INTERVAL 10 SECOND
)
ENGINE = MergeTree
PARTITION BY toYYYYMM(create_time)
ORDER BY id
-- 列字段过期后，会还原为数据类型的默认值。
```

##### 1.1.2 表级别TTL

```sql
CREATE TABLE ttl_table_v2(
id String,
create_time DateTime,
code String TTL create_time + INTERVAL 1 MINUTE,
type UInt8
)ENGINE = MergeTree
PARTITION BY toYYYYMM(create_time)
ORDER BY create_time
TTL create_time + INTERVAL 1 DAY
-- 当触发TTL清理时，那些满足过期时间的数据行将会被整行删除。
```

##### 1.1.3 TTL运行机理

1. MergeTree以分区目录为单位，通过ttl.txt文件记录过期时间，并将其作为后续的判断依据；

2. 每当写入一批数据时，都会基于INTERVAL表达式的计算结果为这个分区生成ttl.txt文件；

>cat ./ttl.txt
>ttl format version: 1
>{"columns":[{"name":"code","min":1557478860,"max":1557651660}],"table":{"min":1557565200,"max":1557738000}}
>// columns用于保存列级别TTL信息 table用于保存表级别TTL信息；
>// min和max则保存了当前数据分区内，TTL指定日期字段的最小值、最大值分别与INTERVAL表达式计算后的时间戳

3. 只有在MergeTree合并分区时，才会触发删除TTL过期数据的逻辑；

4. 在选择删除的分区时，会使用贪婪算法，它的算法规则是尽可能找到会最早过期的，同时年纪又是最老的分区（合并次数更多，MaxBlockNum更大的）；

5. 如果一个分区内某一列数据因为TTL到期全部被删除了，那么在合并之后生成的新分区目录中，将不会包含这个列字段的数据文件（.bin和.mrk）。



tips:

1. TTL默认的合并频率由MergeTree的merge_with_ttl_timeout参数控制，默认86400秒，即1天。它维护的是一个专有的TTL任务队列。有别于MergeTree的常规合并任务;
2. 除了被动触发TTL合并外，也可以使用optimize命令强制触发合并。例如，触发一个分区合并: ` optimize TABLE table_name ` ；触发所有分区合并：` optimize TABLE table_name FINAL `
3. 全局控制TTL合并任务的开启： `SYSTEM STOP (START) TTL MERGES `



#### 1.2 多路径存储

19.15版本后 MergeTree 支持自定义存储策略，以数据分区为最小移动单元，将分区目录写入多块磁盘目录 

- 默认策略

MergeTree原本的存储策略，无需任何配置，所有分区自动保存到config.xml 配置中path 指定路径下。

- JBOD策略

适合服务器挂载了多块磁盘，但没有做RAID的场景。 Just a Bunch of Disks 是一种轮询策略，每执行一次 insert 或merge，所产生的新分区会轮询写入各个磁盘。

- HOT / COLD 策略 

适合服务器挂载了不同类型磁盘的场景。将磁盘分为HOT与COLD两类区域，HOT区域使用SSD这类高性能，COLD则可使用HDD这类高容量存储媒介。

数据在写入MergeTree之初，首先会在HOT区域创建分区目录用于保存数据，当分区数据大小累积到阈值(**max_data_part_size**)时，数据会自行移动到COLD区域。

而在每个区域的内部，也支持定义多个磁盘，所以在单个区域的写入过程中，也能应用JBOD策略。



### 2. ReplacingMergeTree

为了数据去重而设计的，它能够在合并分区时删除重复的数据。

```sql
ENGINE = ReplacingMergeTree(ver)
-- 其中，ver是选填参数，会指定一个UInt*、Date或者DateTime类型的字段作为版本号
```

**去重逻辑**：

1. 使用order by 排序键 作为判断重复数据的唯一键；

2. 只用在合并分区的时候才会触发删除重复数据的逻辑；

3. 以数据分区为单位删除重复数据。当分区合并时，同一分区内的重复数据会被删除，不同分区之间重复数据不会删除；

4. 在进行数据去重时，因为分区内的数据已经基于order by进行了排序，所以能找到那些相邻的重复数据；

5. 数据去重策略两种：

6. 1. 如果没有设置ver 版本号，则保留同一组重复数据中的最后一行；
   2. 设置了ver 版本号，则保留同一组重复数据中ver 字段取值最大的那一行。



### 3. SummingMergeTree

在合并分区的时候按照预先定义的条件聚合汇总数据，将同一分组下的多行数据汇总合并成一行，这样既减少了数据行，又降低了后续汇总查询的开销。

```sql
CREATE TABLE summing_table(
id String,
city String,
v1 UInt32,
v2 Float64,
create_time DateTime
)ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(create_time)
ORDER BY (id, city)
PRIMARY KEY id
```



**处理逻辑：**

1. 用ORBER BY排序键作为聚合数据的条件Key；
2. 只有在合并分区的时候才会触发汇总的逻辑； 
3. 以数据分区为单位来聚合数据。当分区合并时，同一数据分区内聚合Key相同的数据会被合并汇总，而不同分区之间的数据则不会被汇总；
4. 如果在定义引擎时指定了columns汇总列（非主键的数值类型字段），则SUM汇总这些列字段；如果未指定，则聚合所有非主键的数值类型字段；
5. 在进行数据汇总时，因为分区内的数据已经基于ORBER BY排序，所以能够找到相邻且拥有相同聚合Key的数据‘；
6. 在汇总数据时，同一分区内，相同聚合Key的多行数据会合并成一行。其中，汇总字段会进行SUM计算；对于那些非汇总字段，则会使用第一行数据的取值；
7. 支持嵌套结构，但列字段名称必须以Map后缀结尾。嵌套类型中，默认以第一个字段作为聚合Key。除第一个字段以外，任何名称以Key、Id或Type为后缀结尾的字段，都将和第一个字段一起组成复合Key。



eg:

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_21-53-25.png)



支持嵌套类型字段， 在使用**嵌套类型字段**时，需要被SUM汇总的字段名称必须以Map后缀结尾：

```sql
CREATE TABLE summing_table_nested(
id String,
nestMap Nested(
id UInt32,
key UInt32,
val UInt64
),
create_time DateTime
)ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(create_time)
ORDER BY id
```

默认情况下，会以嵌套类型中第一个字段作为聚合条件Key。eg:

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_21-55-46.png)

复合key，在嵌套类型的字段中，除第一个字段以外，任何名称是以Key、Id和Type为后缀结尾的字段，都将和第一个字段一起组成复合Key。

例如将上面的key 改为Key：` nestMap Nested(id UInt32,Key UInt32,val UInt64) ` ，则数据会以id和key作为聚合条件。



### 4. AggregatingMergeTree

> "数据立方体" ： 空间换时间提升查询性能；将需要聚合的数据预先计算出来，并将结果保存起来。在后续聚合查询的时候，直接使用结果数据。
>
> AggregationMergeTree 有些许数据立方体的意思。能够在合并分区的时候，按照预先定义的条件聚合数据。同时根据预先定义的聚合函数计算数据并通过二进制的格式存入表内。将同一分组的多行数据聚合成一行，即减少数据行又降低后续聚合查询的开销。

```sql
CREATE TABLE agg_table(
id String,
city String,
code AggregateFunction(uniq,String),
value AggregateFunction(sum,UInt32),
create_time DateTime
)ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMM(create_time)
ORDER BY (id,city)
PRIMARY KEY id
-- id和city是聚合条件，即group by id, city; 而code和value是聚合字段，即 uniq(code), sum(value)
```



使用：

![](https://resouce-long.oss-cn-hangzhou.aliyuncs.com/database/clickhouse/img/Snipaste_2022-03-17_22-08-11.png)

```sql
SELECT id, sumMerge(value), uniqMerge(code) FROM agg_view GROUP BY id, city
┌─id──┬─sumMerge(value)──┬──uniqMerge(code)─┐
│ A000 │ 200 │ 1 │
│ A000 │ 300 │ 2 │
└─────┴────────────┴────────────┘
```



**处理逻辑：**

1. 用order by排序键作为聚合数据的条件key；
2. 使用AggregateFunction字段类型定义聚合函数的类型以及聚合的字段；
3. 只用在合并分区的时候才会触发聚合计算的逻辑；
4. 以数据分区为单位来聚合数据，当分区合并时，同一数据分区内聚合key相同的数据会被合并计算，而不同分区之间的数据则不会被计算；
5. 在进行数据计算时，因为分区内的数据已经基于orderby排序，所以能够找到那些相邻且拥有相同聚合key的数据；
6. 在聚合数据时，同一分区内，相同聚合key的多行数据会合并成一行，对于那些非主键、非AggregateFunction类型字段，则会使用第一行数据的取值；
7. AggregateFunction类型的字段使用二进制存储，写入数据时，需要调用*State函数；而在查询数据时，则需要调用相应的 *Merge函数；其中 *表示定义时使用的聚合函数；
8. AggregateMergeTree通常作为物化视图的表引擎，与普通MergeTree搭配使用；





### 5. CollapsingMergeTree

CollapsingMergeTree就是一种通过以增代删的思路，支持行级数据修改和删除的表引擎。

> 通过定义一个sign标记位字段，记录数据行的状态。如果sign标记为1，则表示这是一行有效的数据；如果sign标记为-1；
>
> 则表示这行数据需要被删除。当CollapsingMergeTree分区合并时，同一数据分区内，sign标记为1和-1的一组数据会被抵消删除。
>
> 这种1和-1相互抵消的操作，犹如将一张瓦楞纸折叠了一般。

```sql
CREATE TABLE collpase_table(
id String,
code Int32,
create_time DateTime,
sign Int8
)ENGINE = CollapsingMergeTree(sign)
PARTITION BY toYYYYMM(create_time)
ORDER BY id
-- sign 用于指定一个Int8 类型的标志位字段。 
-- 同样是以order by 排序键作为后续判断数据唯一性的依据。
```

CollapsingMergeTree在折叠数据时，遵循以下原则：

1. 如果sign=1 比 sign=-1 的数据多一行，则保留最后一行sign=1的数据；
2. 如果sign=-1 比 sign=1 的数据多一行，则保留第一行sign=-1的数据；
3. 如果sign=1和sign=-1数据行一样多，并且最后一行是sign=1，则保留第一行sign=-1和最后一行sign=1的数据；
4. 如果sign=1和sign=-1 数据行一样多，并且最后一行是sign=-1，则什么也不保留；
5. 其余情况，clickhouse会打印警告日志，但不会报错，在这种情况下，查询结果不可预知；



**注意点：**

1、折叠数据并不是实时触发的，和所有其他的MergeTree变种表引擎一样，这项特性也只有在分区合并的时候才会体现。

所以在分区合并之前，用户还是会看到旧的数据。解决这个问题的方式有两种：

- 在查询数据之前，使用optimize TABLE table_name FINAL命令强制分区合并，但是这种方法效率极低，在实际生产环境中慎用。
- 需要改变我们的查询方式：

```sql
-- 原sql
SELECT id,SUM(code),COUNT(code),AVG(code),uniq(code)
FROM collpase_table
GROUP BY id

-- 改写后的sql
SELECT id,SUM(code * sign),COUNT(code * sign),AVG(code * sign),uniq(code * sign)
FROM collpase_table
GROUP BY id
HAVING SUM(sign) > 0
```

2、CollapsingMergeTree对于写入数据的顺序有着严格要求；先写入sign=-1，再写入sign=1，不能够折叠。

> 这种现象是CollapsingMergeTree的处理机制引起的，因为它要求
> sign=1和sign=-1的数据相邻。而分区内的数据基于ORBER BY排序，要实现
> sign=1和sign=-1的数据相邻，则只能依靠严格按照顺序写入。



### 6.VersionedCollapsingMergeTree

VersionedCollapsingMergeTree表引擎的作用与CollapsingMergeTree完全相同，

它们的不同之处在于，VersionedCollapsingMergeTree对**数据的写入顺序没有要求，在同一个分区内，任意顺序的数据都能够完成折叠操作。** 

```sql
CREATE TABLE ver_collpase_table(
id String,
code Int32,
create_time DateTime,
sign Int8,
ver UInt8
)ENGINE = VersionedCollapsingMergeTree(sign,ver)
PARTITION BY toYYYYMM(create_time)
ORDER BY id
-- 除了需要指定sign标记字段以外，还需要指定一个UInt8类型的ver版本号字段
-- 在定义ver字段之后，VersionedCollapsingMergeTree会自动将ver作为排序条件并增加到ORDER BY的末端。
```

以上面的ver_collpase_table表为例，在每个数据分区内，数据会按照ORDER BY id，ver DESC排序。所以无论写入时数据的顺序如何，在折叠处理时，都能回到正确的顺序。





## 六、其他常见类型表引擎

### 1.外部存储类型



### 2.内存类型

### 3.日志类型

### 4.接口类型

### 5.其他类型



## 七、数据查询



## 八、副本与分片



## 九、管理与运维
